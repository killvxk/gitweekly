# 自动化周报生成工具 - 使用说明

## 📋 功能概述

这个工具可以完全自动化地：
1. 从Git提交历史生成周报markdown文件
2. 使用AI（Anthropic Claude）为GitHub项目生成中文描述
3. 自动更新周报文件中的项目说明

## 🚀 快速开始

### 1. 设置API密钥

```powershell
# Windows PowerShell
$env:ANTHROPIC_API_KEY = "sk-ant-your-api-key-here"
```

```bash
# Linux/Mac
export ANTHROPIC_API_KEY="sk-ant-your-api-key-here"
```

### 2. 运行脚本

```bash
python auto_weekly.py
```

### 3. 选择模式

运行后会显示3个选项：

```
1. 完全自动化（生成周报 + AI描述）← 推荐
2. 仅生成周报文件（不生成描述）
3. 仅为已有周报生成描述
```

## 📊 当前状态

- ✅ 已生成 21 个周报文件
- ✅ 已完成 2 个周报的描述（2025-07-21~27, 2025-07-28~08-03, 2025-12-05~11）
- ⏳ 剩余 **415个链接** 需要AI生成描述

## 🎯 推荐使用方式

### 方式1：完全自动化（一键完成）

```bash
python auto_weekly.py
# 选择: 1
# 起始日期: 2025-07-21 (或直接回车使用默认)
# 每周处理数: 50 (或根据需要调整)
```

这会：
- 扫描Git历史生成所有周报
- 为每个链接调用AI生成中文描述
- 自动更新所有markdown文件

### 方式2：分批处理（推荐用于大量链接）

```bash
python auto_weekly.py
# 选择: 3 (仅生成描述)
# 每周处理数: 20-30 (避免API速率限制)
```

可以多次运行，每次处理一部分，避免：
- API速率限制
- 网络超时
- 意外中断导致进度丢失

## ⚙️ 配置选项

### 环境变量

| 变量名 | 默认值 | 说明 |
|--------|--------|------|
| `ANTHROPIC_API_KEY` | 无 | **必需** - Anthropic API密钥 |
| `AI_MODEL` | `claude-3-5-sonnet-20241022` | 使用的Claude模型 |
| `AI_API_URL` | `https://api.anthropic.com/v1/messages` | API端点 |

### 使用其他模型

```bash
# 使用更便宜的Haiku模型
$env:AI_MODEL = "claude-3-haiku-20240307"

# 使用最强大的Opus模型
$env:AI_MODEL = "claude-opus-4-20250514"
```

## 📁 文件结构

```
f:/gitweekly/
├── auto_weekly.py          # 主脚本
├── auto_generate_weekly.py # 备用脚本（不含Git集成）
├── gen_weekly.py           # 旧的周报生成脚本
├── test_auto_weekly.py     # 测试脚本
├── weekly/                 # 周报目录
│   ├── weekly-2025-07-21_2025-07-27.md
│   ├── weekly-2025-07-28_2025-08-03.md
│   └── ... (21个文件)
└── links_cache/            # 缓存目录
    └── descriptions_cache.json  # AI生成的描述缓存
```

## 🔍 工作原理

### 完整流程

```
Git提交记录
    ↓
按周分组 (周一-周日)
    ↓
提取新增的GitHub链接
    ↓
生成markdown周报文件
    ↓
扫描空白描述的链接
    ↓
直接从raw.githubusercontent.com获取README（无API限制！）
    ↓
发送给AI生成中文摘要
    ↓
更新markdown文件
    ↓
保存到缓存
```

### 优化特性

✅ **无GitHub API限制**
- 使用 `raw.githubusercontent.com` 直接访问README
- 不受GitHub API速率限制（60次/小时）
- 更快、更稳定

### 智能缓存

- 所有AI生成的描述都会缓存在 `links_cache/descriptions_cache.json`
- 重复运行不会重复调用API
- 可以安全地多次运行脚本

## 💡 使用技巧

### 1. 分批处理大量链接

```bash
# 第一批：处理前10个周报
python auto_weekly.py  # 选择3，每周20个

# 第二批：继续处理
python auto_weekly.py  # 再次运行，会跳过已完成的
```

### 2. 查看进度

```bash
# 查看还有多少链接需要处理
python auto_complete_all.py
```

### 3. 手动调整描述

编辑 `links_cache/descriptions_cache.json`：

```json
{
  "https://github.com/example/repo": "修改后的描述"
}
```

然后重新运行脚本更新到markdown文件。

### 4. 测试功能

```bash
# 运行测试脚本验证各模块
python test_auto_weekly.py
```

## ⚠️ 注意事项

### API调用限制

- Claude API有速率限制
- 建议每批处理20-50个链接
- 每个链接间有1秒延迟
- 如遇速率限制，等待几分钟后重试

### GitHub访问

- ✅ 使用 raw.githubusercontent.com **无限制访问**
- 无需GitHub Token
- 不受API速率限制影响

### 网络问题

- 某些GitHub仓库可能已删除或私有
- 脚本会自动跳过失败的链接
- 可以稍后重试失败的链接

## 🐛 故障排除

### 问题1：API返回401错误

```bash
# 检查API Key是否正确设置
echo $env:ANTHROPIC_API_KEY
```

### 问题2：GitHub内容获取失败

```bash
# 检查网络连接
ping github.com

# 或使用代理
$env:HTTP_PROXY = "http://proxy:port"
```

### 问题3：描述质量不理想

```bash
# 使用更强大的模型
$env:AI_MODEL = "claude-3-5-sonnet-20241022"

# 或手动编辑缓存文件
notepad links_cache/descriptions_cache.json
```

### 问题4：进度丢失

不用担心！脚本每5个链接就会保存缓存，重新运行会从缓存恢复。

## 📈 预计处理时间

- **415个链接** × 2秒/链接 ≈ **14分钟**（理想情况）
- 实际可能需要 **20-30分钟**（考虑网络延迟）
- 分批处理可以随时暂停和恢复

## 💰 成本估算

使用 Claude 3.5 Sonnet：
- 每个链接约 ~2000 tokens
- 415个链接 ≈ 830K tokens
- 成本约 $2.5 USD

使用 Claude 3 Haiku（更便宜）：
- 相同工作量约 $0.25 USD

## 🎉 完成后

所有415个链接处理完成后：
- 每个周报文件都会有完整的中文描述
- 可以提交到Git仓库
- 可以继续为新的提交自动生成周报

## 📞 获取帮助

如果遇到问题：
1. 查看脚本输出的错误信息
2. 运行 `python test_auto_weekly.py` 诊断
3. 检查 `links_cache/descriptions_cache.json` 查看已处理的链接

---

**祝使用愉快！** 🚀
